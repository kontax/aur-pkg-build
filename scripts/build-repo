#!/bin/bash
# 
# build-repo
# 
# Build's an AUR repository database from a git repo, as well as adding any
# packages that were built previously to the database. This prevents any
# syncing issues which may have occurred when building multiple packages
# in parallel.
#

set -uo pipefail
IFS=$'\n\t'

region=${AWS_REGION}        # The AWS region the SQS queue is contained in
repo_name=${REPO_NAME}      # The name of the DB file within the repository
repo_bucket=${REPO_BUCKET}  # The bucket name containing  repo files within AWS
arch=${REPO_ARCH}           # The architecture to build for (eg. x86_64)

git_url=$1
pkgs=$2

# Create the temp /pkg folder
if [ -d /pkg ]; then
    rm -r /pkg
fi

mkdir /pkg
chown -R makepkg /pkg


# Save the PKGBUILD and build that
echo "Building PKGBUILD from git repo"
/build-git "$git_url" "$repo_name"

# Store each newly built package in the pkg folder
for built_pkg in $pkgs; do
    echo "Downloading $built_pkg"
    aws s3 sync \
        --region ${region} \
        --acl public-read \
        --exclude "*" \
        --include "${built_pkg}*.pkg.tar.xz*" \
        s3://${repo_bucket}/${arch}/ /pkg/

    # Copy the package and signature to a temp folder
    pushd /pkg
    newpkg=$(ls *.pkg.tar.xz)
    mv "${newpkg}"* /${repo_bucket}/${arch}/

    # Add it to the repo and sign
    pushd /${repo_bucket}/${arch}
    sudo -u makepkg repo-add ${repo_name}.db.tar.xz "${newpkg}" -s
    popd
    popd
done

# Sync up DB and package to s3
aws s3 sync \
    --region ${region} \
    --acl public-read \
    --follow-symlinks \
    /${repo_bucket}/${arch}/ s3://${repo_bucket}/${arch}/

